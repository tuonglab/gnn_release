{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae89a000",
   "metadata": {},
   "source": [
    "## Mathematical Formulation\n",
    "\n",
    "### 1. Sample Skewness\n",
    "\n",
    "$$\n",
    "\\text{skew}(x) =\n",
    "\\begin{cases}\n",
    "0, & n < 3 \\text{ or } \\sigma = 0, \\\\[6pt]\n",
    "\\dfrac{\\frac{1}{n} \\sum_{i=1}^n (x_i - \\mu)^3}{\\sigma^3}, & \\text{otherwise.}\n",
    "\\end{cases}\n",
    "\\tag{1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mu = \\frac{1}{n} \\sum_{i=1}^n x_i, \\quad\n",
    "\\sigma = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (x_i - \\mu)^2}.\n",
    "\\tag{2}\n",
    "$$\n",
    "\n",
    "\n",
    "### 2. Skew-Aware Score Adjustment\n",
    "\n",
    "$$\n",
    "a = -\\tanh\\!\\big(\\text{skew}(P) \\cdot \\lambda_s\\big) \\cdot \\lambda_c\n",
    "\\tag{3}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P' = \\mathrm{clip}(P + a, f, c)\n",
    "\\tag{4}\n",
    "$$\n",
    "\n",
    "where $ \\lambda_s $ is the skew sensitivity, $ \\lambda_c $ is the clipping strength, and $(f, c)$ are the lower and upper bounds (typically $0$ and $1$).\n",
    "\n",
    "\n",
    "### 3. High-Confidence Scoreâ€“Frequency Blending\n",
    "\n",
    "$$\n",
    "M_h = \\mathbb{I}(P > p_h) \\cdot \\mathbb{I}(R > f_h), \\quad\n",
    "M_l = \\mathbb{I}(P < 1 - p_h) \\cdot \\mathbb{I}(R < 1 - f_h)\n",
    "\\tag{5}\n",
    "$$\n",
    "\n",
    "$$\n",
    "A_h = \\min(P, R) \\cdot M_h, \\quad\n",
    "A_l = \\min(1 - P, 1 - R) \\cdot M_l\n",
    "\\tag{6}\n",
    "$$\n",
    "\n",
    "$$\n",
    "S_{\\text{adj}} = P + \\alpha A_h - \\beta A_l\n",
    "\\tag{7}\n",
    "$$\n",
    "\n",
    "$$\n",
    "S = (1 - \\gamma) P + \\gamma S_{\\text{adj}}\n",
    "\\tag{8}\n",
    "$$\n",
    "\n",
    "$$\n",
    "S' = \\mathrm{clip}(S, 0, 1)\n",
    "\\tag{9}\n",
    "$$\n",
    "\n",
    "\n",
    "### 4. Full Pipeline\n",
    "\n",
    "$$\n",
    "\\text{blend} = \\text{combined\\_score\\_sample\\_blend}(P, F_{\\text{raw}})\n",
    "\\tag{10}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{score\\_adj} = \\text{combined\\_score\\_distribution\\_aware\\_simple}(\\text{blend})\n",
    "\\tag{11}\n",
    "$$\n",
    "\n",
    "\n",
    "### 5. Variable Definitions\n",
    "\n",
    "| Symbol | Meaning |\n",
    "|:--------|:---------|\n",
    "| $x_i$ | Individual data sample |\n",
    "| $n$ | Number of samples |\n",
    "| $\\mu$ | Mean of samples |\n",
    "| $\\sigma$ | Standard deviation |\n",
    "| $P$ | Base model score (probability) |\n",
    "| $F_{\\text{raw}}$ | Raw clone frequency |\n",
    "| $R$ | Percentile-normalized frequency, $R = F_{\\text{percentile}}(F_{\\text{raw}})$ |\n",
    "| $p_h, f_h$ | High-confidence thresholds for $P$ and $R$ |\n",
    "| $M_h, M_l$ | Masks for high and low confidence regions |\n",
    "| $A_h, A_l$ | Adjustment terms for high and low confidence |\n",
    "| $\\alpha, \\beta, \\gamma$ | Blend coefficients controlling balance and smoothing |\n",
    "| $\\lambda_s$ | Skew sensitivity (scaling factor) |\n",
    "| $\\lambda_c$ | Clipping limit for skew adjustment |\n",
    "| $(f, c)$ | Lower and upper clipping bounds |\n",
    "| $a$ | Global skew-based adjustment |\n",
    "| $S, S_{\\text{adj}}, S'$ | Intermediate and final adjusted scores |\n",
    "| $\\mathrm{clip}(\\cdot)$ | Truncation to a specified range (e.g. $[0, 1]$) |\n",
    "| $\\mathbb{I}(\\cdot)$ | Indicator function (1 if condition true, else 0) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c04db0a",
   "metadata": {},
   "source": [
    "## Intuitive Explanation of the Inverse Logit Mean\n",
    "\n",
    "The **inverse logit mean** is a way to average probabilities more accurately when they come from models that use a *logit (log-odds)* scale internally.\n",
    "\n",
    "In simple terms:\n",
    "\n",
    "1. **Convert all probabilities to the logit scale** â€”  \n",
    "   this turns curved probability values (between 0 and 1) into linear \"log-odds\" values (from âˆ’âˆž to +âˆž).\n",
    "\n",
    "2. **Take the average (mean) of these logit values** â€”  \n",
    "   since logits are linear, averaging here makes statistical sense.\n",
    "\n",
    "3. **Convert the mean logit back to probability space** using the inverse logit (sigmoid) function â€”  \n",
    "   this gives a single representative probability on the familiar 0â€“1 scale.\n",
    "\n",
    "Mathematically:\n",
    "\n",
    "$$\n",
    "\\text{logit}(p) = \\log\\!\\left(\\frac{p}{1 - p}\\right)\n",
    "\\tag{1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{invlogit}(x) = \\frac{1}{1 + e^{-x}}\n",
    "\\tag{2}\n",
    "$$\n",
    "\n",
    "So the **inverse logit mean** of a set of probabilities $\\{p_i\\}$ is:\n",
    "\n",
    "$$\n",
    "\\mathrm{ILM}(p_1, p_2, \\ldots, p_n)\n",
    "= \\mathrm{invlogit}\\!\\left( \\frac{1}{n} \\sum_{i=1}^n \\text{logit}(p_i) \\right)\n",
    "\\tag{3}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ” Why do this?\n",
    "\n",
    "Averaging probabilities directly can be misleading because probabilities are *nonlinear*.  \n",
    "By first moving to the **logit (log-odds)** space, you average on a scale where changes are symmetric and linear.  \n",
    "Then, converting back with the inverse logit gives a more accurate \"average\" probability â€”  \n",
    "especially when probabilities are close to 0 or 1.\n",
    "\n",
    "---\n",
    "\n",
    "**Example intuition:**\n",
    "\n",
    "If two events have probabilities 0.1 and 0.9:  \n",
    "- A direct average gives 0.5.  \n",
    "- But in logit space:  \n",
    "  $\\text{logit}(0.1) = -2.197$, $\\text{logit}(0.9) = +2.197$.  \n",
    "  Their mean logit is $0$, and $\\text{invlogit}(0) = 0.5$.  \n",
    "\n",
    "That one happens to match â€” but for less symmetric cases (like 0.2 and 0.6),  \n",
    "the inverse logit mean will better reflect the modelâ€™s underlying uncertainty.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
