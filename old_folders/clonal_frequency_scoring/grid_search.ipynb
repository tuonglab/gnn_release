{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ccbaa93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA_seq</th>\n",
       "      <th>CloneFreq</th>\n",
       "      <th>prob</th>\n",
       "      <th>high</th>\n",
       "      <th>transformed_score</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASASDGAGDQPQHF</td>\n",
       "      <td>0.037352</td>\n",
       "      <td>0.920785</td>\n",
       "      <td>True</td>\n",
       "      <td>3.439338e-02</td>\n",
       "      <td>S2_merged.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CASSRAPASTEAFF</td>\n",
       "      <td>0.037352</td>\n",
       "      <td>0.423499</td>\n",
       "      <td>False</td>\n",
       "      <td>1.581865e-02</td>\n",
       "      <td>S2_merged.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CASSPGQGELFF</td>\n",
       "      <td>0.011348</td>\n",
       "      <td>0.256990</td>\n",
       "      <td>False</td>\n",
       "      <td>2.916200e-03</td>\n",
       "      <td>S2_merged.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSARDRGGENTGELFF</td>\n",
       "      <td>0.008983</td>\n",
       "      <td>0.991506</td>\n",
       "      <td>True</td>\n",
       "      <td>8.907149e-03</td>\n",
       "      <td>S2_merged.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CSVPGTDYNEQFF</td>\n",
       "      <td>0.008983</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>False</td>\n",
       "      <td>4.219959e-05</td>\n",
       "      <td>S2_merged.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5629</th>\n",
       "      <td>CSAPGTQIYEQYF</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.251051</td>\n",
       "      <td>False</td>\n",
       "      <td>9.693102e-05</td>\n",
       "      <td>S3_merged.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5630</th>\n",
       "      <td>CASSLQVIGTDTQYF</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.384414</td>\n",
       "      <td>False</td>\n",
       "      <td>1.484223e-04</td>\n",
       "      <td>S3_merged.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631</th>\n",
       "      <td>CASSLTGLNTEAFF</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>False</td>\n",
       "      <td>1.004468e-07</td>\n",
       "      <td>S3_merged.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5632</th>\n",
       "      <td>CASSFQGTVYEQYF</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.529522</td>\n",
       "      <td>False</td>\n",
       "      <td>2.044488e-04</td>\n",
       "      <td>S3_merged.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5633</th>\n",
       "      <td>CASSRSGELFF</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>False</td>\n",
       "      <td>5.066862e-06</td>\n",
       "      <td>S3_merged.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5634 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                AA_seq  CloneFreq      prob   high  transformed_score  \\\n",
       "0      CASASDGAGDQPQHF   0.037352  0.920785   True       3.439338e-02   \n",
       "1       CASSRAPASTEAFF   0.037352  0.423499  False       1.581865e-02   \n",
       "2         CASSPGQGELFF   0.011348  0.256990  False       2.916200e-03   \n",
       "3     CSARDRGGENTGELFF   0.008983  0.991506   True       8.907149e-03   \n",
       "4        CSVPGTDYNEQFF   0.008983  0.004697  False       4.219959e-05   \n",
       "...                ...        ...       ...    ...                ...   \n",
       "5629     CSAPGTQIYEQYF   0.000386  0.251051  False       9.693102e-05   \n",
       "5630   CASSLQVIGTDTQYF   0.000386  0.384414  False       1.484223e-04   \n",
       "5631    CASSLTGLNTEAFF   0.000386  0.000260  False       1.004468e-07   \n",
       "5632    CASSFQGTVYEQYF   0.000386  0.529522  False       2.044488e-04   \n",
       "5633       CASSRSGELFF   0.000386  0.013123  False       5.066862e-06   \n",
       "\n",
       "        source_file  \n",
       "0     S2_merged.csv  \n",
       "1     S2_merged.csv  \n",
       "2     S2_merged.csv  \n",
       "3     S2_merged.csv  \n",
       "4     S2_merged.csv  \n",
       "...             ...  \n",
       "5629  S3_merged.csv  \n",
       "5630  S3_merged.csv  \n",
       "5631  S3_merged.csv  \n",
       "5632  S3_merged.csv  \n",
       "5633  S3_merged.csv  \n",
       "\n",
       "[5634 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Directory path\n",
    "csv_dir = (\n",
    "    \"/scratch/project/tcr_ml/gnn_release/icantcrscoring/model_2025_sc_curated/seekgene\"\n",
    ")\n",
    "\n",
    "# Get all CSV files in the directory\n",
    "csv_files = [\n",
    "    f\n",
    "    for f in glob.glob(os.path.join(csv_dir, \"*.csv\"))\n",
    "    if os.path.basename(f) != \"summary.csv\"\n",
    "]\n",
    "# Load all CSV files into a list of DataFrames\n",
    "dataframes = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    # Optional: add a column to track which file the data came from\n",
    "    df[\"source_file\"] = os.path.basename(file)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# If you want to combine all DataFrames into one\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "072e52d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA_seq</th>\n",
       "      <th>CloneFreq</th>\n",
       "      <th>prob</th>\n",
       "      <th>high</th>\n",
       "      <th>transformed_score</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASTPGDEQYF</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>0.575344</td>\n",
       "      <td>False</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>20240918_WGS_20240924_sc_PICA0008-PICA0032_Poo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CASSLGSGQYF</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.588268</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>20240918_WGS_20240924_sc_PICA0008-PICA0032_Poo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CASSLGSGQYF</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.588268</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>20240918_WGS_20240924_sc_PICA0008-PICA0032_Poo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CASSLGSGQYF</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.588268</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>20240918_WGS_20240924_sc_PICA0008-PICA0032_Poo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CASSLGSGQYF</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.588268</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>20240918_WGS_20240924_sc_PICA0008-PICA0032_Poo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149200</th>\n",
       "      <td>CATSDSTRGDSYNEQFF</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.144616</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>20241106_WGS_20241106_sc_PICA0033-PICA0069_Poo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149201</th>\n",
       "      <td>CSAGGDRSNQPQHF</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.086664</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>20241106_WGS_20241106_sc_PICA0033-PICA0069_Poo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149202</th>\n",
       "      <td>CSAREPGSSPLHF</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.909164</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>20241106_WGS_20241106_sc_PICA0033-PICA0069_Poo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149203</th>\n",
       "      <td>CAISETSEVGYEQYF</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.329552</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>20241106_WGS_20241106_sc_PICA0033-PICA0069_Poo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149204</th>\n",
       "      <td>CASSPIFSSYEQYF</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.326521</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>20241106_WGS_20241106_sc_PICA0033-PICA0069_Poo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149205 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   AA_seq  CloneFreq      prob   high  transformed_score  \\\n",
       "0             CASTPGDEQYF   0.003607  0.575344  False           0.002075   \n",
       "1             CASSLGSGQYF   0.001945  0.588268  False           0.001144   \n",
       "2             CASSLGSGQYF   0.001945  0.588268  False           0.001144   \n",
       "3             CASSLGSGQYF   0.001945  0.588268  False           0.001144   \n",
       "4             CASSLGSGQYF   0.001945  0.588268  False           0.001144   \n",
       "...                   ...        ...       ...    ...                ...   \n",
       "149200  CATSDSTRGDSYNEQFF   0.000038  0.144616  False           0.000005   \n",
       "149201     CSAGGDRSNQPQHF   0.000038  0.086664  False           0.000003   \n",
       "149202      CSAREPGSSPLHF   0.000038  0.909164   True           0.000035   \n",
       "149203    CAISETSEVGYEQYF   0.000038  0.329552  False           0.000013   \n",
       "149204     CASSPIFSSYEQYF   0.000038  0.326521  False           0.000012   \n",
       "\n",
       "                                              source_file  \n",
       "0       20240918_WGS_20240924_sc_PICA0008-PICA0032_Poo...  \n",
       "1       20240918_WGS_20240924_sc_PICA0008-PICA0032_Poo...  \n",
       "2       20240918_WGS_20240924_sc_PICA0008-PICA0032_Poo...  \n",
       "3       20240918_WGS_20240924_sc_PICA0008-PICA0032_Poo...  \n",
       "4       20240918_WGS_20240924_sc_PICA0008-PICA0032_Poo...  \n",
       "...                                                   ...  \n",
       "149200  20241106_WGS_20241106_sc_PICA0033-PICA0069_Poo...  \n",
       "149201  20241106_WGS_20241106_sc_PICA0033-PICA0069_Poo...  \n",
       "149202  20241106_WGS_20241106_sc_PICA0033-PICA0069_Poo...  \n",
       "149203  20241106_WGS_20241106_sc_PICA0033-PICA0069_Poo...  \n",
       "149204  20241106_WGS_20241106_sc_PICA0033-PICA0069_Poo...  \n",
       "\n",
       "[149205 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directory path\n",
    "csv_dir = (\n",
    "    \"/scratch/project/tcr_ml/gnn_release/icantcrscoring/model_2025_sc_curated/PICA\"\n",
    ")\n",
    "\n",
    "# Get all CSV files in the directory\n",
    "csv_files = [\n",
    "    f\n",
    "    for f in glob.glob(os.path.join(csv_dir, \"*.csv\"))\n",
    "    if os.path.basename(f) != \"summary.csv\"\n",
    "]\n",
    "# Load all CSV files into a list of DataFrames\n",
    "dataframes = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    # Optional: add a column to track which file the data came from\n",
    "    df[\"source_file\"] = os.path.basename(file)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# If you want to combine all DataFrames into one\n",
    "combined_control_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "combined_control_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1511db0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (3) does not match length of index (12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 213\u001b[0m\n\u001b[1;32m    210\u001b[0m tmp_cancer  \u001b[38;5;241m=\u001b[39m combined_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_file\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprob\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mcopy();  tmp_cancer[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore_adj\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;241m=\u001b[39m S_c\n\u001b[1;32m    211\u001b[0m tmp_control \u001b[38;5;241m=\u001b[39m combined_control_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_file\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprob\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mcopy(); tmp_control[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore_adj\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m S_k\n\u001b[0;32m--> 213\u001b[0m sm_c \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_metric_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp_cancer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m sm_k \u001b[38;5;241m=\u001b[39m build_metric_table(tmp_control)\n\u001b[1;32m    216\u001b[0m metrics_this \u001b[38;5;241m=\u001b[39m present_metrics(sm_c, sm_k)\n",
      "Cell \u001b[0;32mIn[7], line 144\u001b[0m, in \u001b[0;36mbuild_metric_table\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_metric_table\u001b[39m(df):\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# compute metrics wide, then melt using a temp value name to avoid clashes\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     wide \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    143\u001b[0m         \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msource_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore_adj\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m--> 144\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msummarize_probs\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m           \u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m    146\u001b[0m           \u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevel_1\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m    147\u001b[0m     )\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;66;03m# after the apply, columns are [\"source_file\", \"arithmetic_mean\", \"median\", ...]\u001b[39;00m\n\u001b[1;32m    149\u001b[0m     wide \u001b[38;5;241m=\u001b[39m wide\u001b[38;5;241m.\u001b[39mloc[:, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marithmetic_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometric_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minv_logit_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "File \u001b[0;32m/scratch/project_mnt/S0163/gnn_env/lib/python3.11/site-packages/pandas/core/groupby/generic.py:230\u001b[0m, in \u001b[0;36mSeriesGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(\n\u001b[1;32m    225\u001b[0m     _apply_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemplate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m, examples\u001b[38;5;241m=\u001b[39m_apply_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries_examples\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    227\u001b[0m     )\n\u001b[1;32m    228\u001b[0m )\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[0;32m--> 230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/project_mnt/S0163/gnn_env/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1824\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, include_groups, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1822\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1823\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1824\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1825\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1826\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, Series)\n\u001b[1;32m   1827\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1828\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1829\u001b[0m         ):\n\u001b[1;32m   1830\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1831\u001b[0m                 message\u001b[38;5;241m=\u001b[39m_apply_groupings_depr\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1832\u001b[0m                     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1835\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1836\u001b[0m             )\n",
      "File \u001b[0;32m/scratch/project_mnt/S0163/gnn_env/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1889\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1887\u001b[0m     not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n\u001b[0;32m-> 1889\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap_applied_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnot_indexed_same\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1894\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/project_mnt/S0163/gnn_env/lib/python3.11/site-packages/pandas/core/groupby/generic.py:436\u001b[0m, in \u001b[0;36mSeriesGroupBy._wrap_applied_output\u001b[0;34m(self, data, values, not_indexed_same, is_transform)\u001b[0m\n\u001b[1;32m    434\u001b[0m     result\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_index \u001b[38;5;129;01mand\u001b[39;00m not_indexed_same:\n\u001b[0;32m--> 436\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_insert_inaxis_grouper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m     result\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(result))\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/scratch/project_mnt/S0163/gnn_env/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1551\u001b[0m, in \u001b[0;36mGroupBy._insert_inaxis_grouper\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[1;32m   1550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m in_axis:\n\u001b[0;32m-> 1551\u001b[0m         \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1552\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1553\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1554\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA grouping was used that is not in the columns of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame and so was excluded from the result. This grouping \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be included in a future version of pandas. Add the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1557\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrouping as a column of the DataFrame to silence this warning.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1558\u001b[0m         )\n",
      "File \u001b[0;32m/scratch/project_mnt/S0163/gnn_env/lib/python3.11/site-packages/pandas/core/frame.py:5171\u001b[0m, in \u001b[0;36mDataFrame.insert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   5168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m   5169\u001b[0m     value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 5171\u001b[0m value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39minsert(loc, column, value, refs\u001b[38;5;241m=\u001b[39mrefs)\n",
      "File \u001b[0;32m/scratch/project_mnt/S0163/gnn_env/lib/python3.11/site-packages/pandas/core/frame.py:5266\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 5266\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5267\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   5268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5269\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[1;32m   5270\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5273\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[1;32m   5274\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/project_mnt/S0163/gnn_env/lib/python3.11/site-packages/pandas/core/common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (3) does not match length of index (12)"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------- assumes combined_df and combined_control_df already exist ----------\n",
    "\n",
    "\n",
    "# Reuse your utilities\n",
    "def fraction_to_percentile(\n",
    "    x, weights=None, method=\"hazen\", open_interval=False, eps=1e-9, nan_policy=\"omit\"\n",
    "):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    n = x.size\n",
    "    if n == 0:\n",
    "        return x\n",
    "    has_nan = np.isnan(x).any()\n",
    "    if has_nan:\n",
    "        if nan_policy == \"raise\":\n",
    "            raise ValueError(\"NaNs present with nan_policy='raise'.\")\n",
    "        if nan_policy == \"propagate\":\n",
    "            return np.full_like(x, np.nan, dtype=float)\n",
    "    if weights is None:\n",
    "        w = np.ones_like(x, dtype=float)\n",
    "    else:\n",
    "        w = np.asarray(weights, dtype=float)\n",
    "        if w.shape != x.shape:\n",
    "            raise ValueError(\"weights must have same shape as x\")\n",
    "        if np.any(w < 0):\n",
    "            raise ValueError(\"weights must be nonnegative\")\n",
    "\n",
    "    valid = ~np.isnan(x)\n",
    "    xv = x[valid]\n",
    "    wv = w[valid]\n",
    "    m = xv.size\n",
    "    out = np.full_like(x, np.nan, dtype=float)\n",
    "    if m == 0:\n",
    "        return out\n",
    "    if m == 1:\n",
    "        out[valid] = 0.5\n",
    "        return out\n",
    "\n",
    "    order = np.argsort(xv, kind=\"mergesort\")\n",
    "    xv_sorted = xv[order]\n",
    "    wv_sorted = wv[order]\n",
    "\n",
    "    def _midranks_for_ties(sorted_vals_len: int, diffs: np.ndarray):\n",
    "        m = sorted_vals_len\n",
    "        if m == 0:\n",
    "            return np.empty(0, dtype=float)\n",
    "        boundaries = np.flatnonzero(diffs != 0.0)\n",
    "        starts = np.r_[0, boundaries + 1]\n",
    "        stops = np.r_[boundaries, m - 1]\n",
    "        ranks = np.empty(m, dtype=float)\n",
    "        for s, e in zip(starts, stops):\n",
    "            mid = (s + e) / 2.0\n",
    "            ranks[s : e + 1] = mid + 1.0\n",
    "        return ranks\n",
    "\n",
    "    def _plotting_position(ranks, m, method: str):\n",
    "        if method == \"weibull\":\n",
    "            return ranks / (m + 1.0)\n",
    "        if method == \"hazen\":\n",
    "            return (ranks - 0.5) / m\n",
    "        if method == \"blom\":\n",
    "            return (ranks - 0.375) / (m + 0.25)\n",
    "        if method == \"bernard\":\n",
    "            return (ranks - 3.0 / 8.0) / (m + 0.25)\n",
    "        if method == \"rank\":\n",
    "            return np.full(m, 0.5) if m == 1 else (ranks - 1.0) / (m - 1.0)\n",
    "        raise ValueError(f\"Unknown method '{method}'\")\n",
    "\n",
    "    if weights is None or np.allclose(wv_sorted, 1.0):\n",
    "        diffs = np.diff(xv_sorted)\n",
    "        ranks = _midranks_for_ties(len(xv_sorted), diffs)\n",
    "        p_sorted = _plotting_position(ranks, m, method)\n",
    "    else:\n",
    "        uniq_vals, idx_start, counts = np.unique(\n",
    "            xv_sorted, return_index=True, return_counts=True\n",
    "        )\n",
    "        group_weights = np.add.reduceat(wv_sorted, idx_start)\n",
    "        cw = np.cumsum(group_weights)\n",
    "        total = cw[-1]\n",
    "        cw_prev = cw - group_weights\n",
    "        p_group = (cw_prev + 0.5 * group_weights) / total\n",
    "        p_sorted = np.repeat(p_group, counts)\n",
    "\n",
    "    inv = np.empty(m, dtype=int)\n",
    "    inv[order] = np.arange(m)\n",
    "    out[valid] = p_sorted[inv]\n",
    "    if open_interval:\n",
    "        out[out <= 0.0] = eps\n",
    "        out[out >= 1.0] = 1.0 - eps\n",
    "    return out\n",
    "\n",
    "\n",
    "def combined_score_sample_capped(\n",
    "    P,\n",
    "    F_raw,\n",
    "    t_P=0.5,\n",
    "    t_R=0.5,\n",
    "    alpha=0.6,\n",
    "    beta=0.9,\n",
    "    delta_max=0.25,\n",
    "    floor=0.01,\n",
    "    ceil=0.99,\n",
    "):\n",
    "    P = np.clip(np.asarray(P, dtype=float), 0.0, 1.0)\n",
    "    R = fraction_to_percentile(F_raw)\n",
    "\n",
    "    mask_high = (P > t_P) & (R > t_R)\n",
    "    mask_low = (P < t_P) & (R < t_R)\n",
    "\n",
    "    A_high = np.where(mask_high, np.minimum(P, R), 0.0)\n",
    "    A_low = np.where(mask_low, np.minimum(1.0 - P, 1.0 - R), 0.0)\n",
    "\n",
    "    delta = alpha * A_high - beta * A_low\n",
    "    delta = np.clip(delta, -delta_max, delta_max)\n",
    "\n",
    "    S = np.clip(P + delta, floor, ceil)\n",
    "    return S, R\n",
    "\n",
    "\n",
    "def summarize_probs(x):\n",
    "    x = np.clip(np.asarray(x, dtype=float), 1e-9, 1 - 1e-9)\n",
    "    logits = np.log(x / (1 - x))\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"arithmetic_mean\": np.mean(x),\n",
    "            \"median\": np.median(x),\n",
    "            \"geometric_mean\": np.exp(np.mean(np.log(x))),\n",
    "            \"inv_logit_mean\": 1 / (1 + np.exp(-np.mean(logits))),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def build_metric_table(df):\n",
    "    # metrics over score_adj per source file\n",
    "    sm = df.groupby(\"source_file\")[\"score_adj\"].apply(summarize_probs).reset_index()\n",
    "\n",
    "    # reshape to long using a temp value_name that does not collide\n",
    "    sm_long = sm.melt(\n",
    "        id_vars=\"source_file\", var_name=\"level_1\", value_name=\"metric_value\"\n",
    "    )\n",
    "\n",
    "    # baseline mean of original prob for comparison\n",
    "    old_means = (\n",
    "        df.groupby(\"source_file\")[\"prob\"]\n",
    "        .mean()\n",
    "        .rename(\"metric_value\")  # match temp name\n",
    "        .reset_index()\n",
    "    )\n",
    "    old_means[\"level_1\"] = \"old_arithmetic_mean\"\n",
    "\n",
    "    # combine and standardize column name\n",
    "    out = pd.concat(\n",
    "        [\n",
    "            sm_long[[\"source_file\", \"level_1\", \"metric_value\"]],\n",
    "            old_means[[\"source_file\", \"level_1\", \"metric_value\"]],\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    ).rename(columns={\"metric_value\": \"score_adj\"})\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def roc_curve_manual(y_true: np.ndarray, y_score: np.ndarray):\n",
    "    y_true = y_true.astype(int)\n",
    "    order = np.argsort(-y_score)\n",
    "    y_true_sorted = y_true[order]\n",
    "    y_score_sorted = y_score[order]\n",
    "    P = y_true_sorted.sum()\n",
    "    N = len(y_true_sorted) - P\n",
    "    if P == 0 or N == 0:\n",
    "        return np.array([0.0, 1.0]), np.array([0.0, 1.0]), np.nan\n",
    "    tps = np.cumsum(y_true_sorted)\n",
    "    fps = np.cumsum(1 - y_true_sorted)\n",
    "    diffs = np.diff(y_score_sorted)\n",
    "    idx = np.where(diffs != 0)[0]\n",
    "    idx = np.r_[idx, len(y_true_sorted) - 1]\n",
    "    tpr = tps[idx] / P\n",
    "    fpr = fps[idx] / N\n",
    "    tpr = np.r_[0.0, tpr]\n",
    "    fpr = np.r_[0.0, fpr]\n",
    "    auc = np.trapz(tpr, fpr)\n",
    "    return fpr, tpr, auc\n",
    "\n",
    "\n",
    "def compute_auc_for_metrics(df_cancer_long, df_control_long, metrics):\n",
    "    # combine and compute AUC for each metric\n",
    "    dfc = df_cancer_long.copy()\n",
    "    dfc[\"group\"] = \"cancer\"\n",
    "    dfk = df_control_long.copy()\n",
    "    dfk[\"group\"] = \"control\"\n",
    "    df_long = pd.concat([dfc, dfk], ignore_index=True)\n",
    "    out = {}\n",
    "    for m in metrics:\n",
    "        sub = df_long[df_long[\"level_1\"] == m].dropna(subset=[\"score_adj\", \"group\"])\n",
    "        if sub.empty:\n",
    "            out[m] = np.nan\n",
    "            continue\n",
    "        y_true = (sub[\"group\"].values == \"cancer\").astype(int)\n",
    "        y_score = sub[\"score_adj\"].astype(float).values\n",
    "        _, _, auc = roc_curve_manual(y_true, y_score)\n",
    "        out[m] = auc\n",
    "    return out\n",
    "\n",
    "\n",
    "# Define the grid\n",
    "alpha_grid = np.linspace(0.0, 8.0, 33)  # step 0.25\n",
    "beta_grid = np.r_[\n",
    "    np.logspace(-4, -1, 7), np.linspace(0.2, 1.0, 9)\n",
    "]  # 1e-4..0.1 log, then 0.2..1.0 linear\n",
    "\n",
    "# Choose which metrics to optimize\n",
    "metrics_all = [\n",
    "    \"old_arithmetic_mean\",\n",
    "    \"arithmetic_mean\",\n",
    "    \"median\",\n",
    "    \"geometric_mean\",\n",
    "    \"inv_logit_mean\",\n",
    "]\n",
    "metrics_all = [\n",
    "    m\n",
    "    for m in metrics_all\n",
    "    if m\n",
    "    in set(\n",
    "        [\n",
    "            \"old_arithmetic_mean\",\n",
    "            \"arithmetic_mean\",\n",
    "            \"median\",\n",
    "            \"geometric_mean\",\n",
    "            \"inv_logit_mean\",\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "\n",
    "# Storage\n",
    "auc_cube = {m: np.full((len(alpha_grid), len(beta_grid)), np.nan) for m in metrics_all}\n",
    "\n",
    "# Pre-extract base arrays to avoid repeated Series access cost\n",
    "P_cancer = combined_df[\"prob\"].to_numpy(float)\n",
    "F_cancer = combined_df[\"CloneFreq\"].to_numpy(float)\n",
    "P_control = combined_control_df[\"prob\"].to_numpy(float)\n",
    "F_control = combined_control_df[\"CloneFreq\"].to_numpy(float)\n",
    "\n",
    "# Fixed thresholds and clipping as in your code\n",
    "kw = dict(t_P=0.5, t_R=0.5, delta_max=0.25, floor=0.01, ceil=0.99)\n",
    "\n",
    "# Grid search\n",
    "for i, a in enumerate(alpha_grid):\n",
    "    for j, b in enumerate(beta_grid):\n",
    "        # adjust scores\n",
    "        S_c, R_c = combined_score_sample_capped(\n",
    "            P=P_cancer, F_raw=F_cancer, alpha=a, beta=b, **kw\n",
    "        )\n",
    "        S_k, R_k = combined_score_sample_capped(\n",
    "            P=P_control, F_raw=F_control, alpha=a, beta=b, **kw\n",
    "        )\n",
    "\n",
    "        # build temp dataframes\n",
    "        tmp_cancer = combined_df[[\"source_file\", \"prob\"]].copy()\n",
    "        tmp_control = combined_control_df[[\"source_file\", \"prob\"]].copy()\n",
    "        tmp_cancer[\"score_adj\"] = S_c\n",
    "        tmp_control[\"score_adj\"] = S_k\n",
    "\n",
    "        # build per-metric tables\n",
    "        sm_c = build_metric_table(tmp_cancer)\n",
    "        sm_k = build_metric_table(tmp_control)\n",
    "\n",
    "        # compute auc per metric\n",
    "        aucs = compute_auc_for_metrics(sm_c, sm_k, metrics_all)\n",
    "        for m in metrics_all:\n",
    "            auc_cube[m][i, j] = aucs[m]\n",
    "\n",
    "# Find the best alpha and beta for each metric\n",
    "best_rows = []\n",
    "for m in metrics_all:\n",
    "    mat = auc_cube[m]\n",
    "    idx = np.nanargmax(mat)\n",
    "    i, j = np.unravel_index(idx, mat.shape)\n",
    "    best_rows.append(\n",
    "        {\n",
    "            \"metric\": m,\n",
    "            \"best_alpha\": float(alpha_grid[i]),\n",
    "            \"best_beta\": float(beta_grid[j]),\n",
    "            \"best_auc\": float(mat[i, j]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "best_df = pd.DataFrame(best_rows).sort_values(\"best_auc\", ascending=False)\n",
    "print(\"Best alpha and beta per metric based on AUROC\\n\")\n",
    "print(best_df.to_string(index=False))\n",
    "\n",
    "# Plot heatmaps per metric\n",
    "n_metrics = len(metrics_all)\n",
    "ncols = 2\n",
    "nrows = int(np.ceil(n_metrics / ncols))\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, 4 * nrows))\n",
    "\n",
    "axes = np.array(axes).reshape(-1)\n",
    "for k, m in enumerate(metrics_all):\n",
    "    ax = axes[k]\n",
    "    Z = auc_cube[m]\n",
    "    im = ax.imshow(\n",
    "        Z,\n",
    "        origin=\"lower\",\n",
    "        aspect=\"auto\",\n",
    "        extent=[beta_grid.min(), beta_grid.max(), alpha_grid.min(), alpha_grid.max()],\n",
    "    )\n",
    "    ax.set_title(f\"AUROC heatmap - {m}\")\n",
    "    ax.set_xlabel(\"beta\")\n",
    "    ax.set_ylabel(\"alpha\")\n",
    "    # mark best point\n",
    "    idx = np.nanargmax(Z)\n",
    "    i, j = np.unravel_index(idx, Z.shape)\n",
    "    ax.plot(beta_grid[j], alpha_grid[i], marker=\"o\", markersize=6)\n",
    "    fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "# remove empty subplots if any\n",
    "for q in range(k + 1, len(axes)):\n",
    "    fig.delaxes(axes[q])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: line plot of best AUROC by metric\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(best_df[\"metric\"], best_df[\"best_auc\"], marker=\"o\")\n",
    "plt.title(\"Best AUROC by metric\")\n",
    "plt.xlabel(\"Metric\")\n",
    "plt.ylabel(\"Best AUROC\")\n",
    "plt.xticks(rotation=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
